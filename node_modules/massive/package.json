{
  "name": "massive",
  "version": "2.0.9",
  "description": "A small query tool for Postgres that embraces json and makes life simpler",
  "main": "index.js",
  "bin": {
    "massive": "bin/massive.js"
  },
  "directories": {
    "example": "example",
    "test": "test"
  },
  "scripts": {
    "test": "mocha ."
  },
  "keywords": [
    "postgres",
    "pg",
    "postgresql"
  ],
  "author": {
    "name": "Rob Conery",
    "email": "robconery@gmail.com"
  },
  "contributors": [
    {
      "name": "Karl Seguin",
      "email": "karl@openmymind.net"
    },
    {
      "name": "John Atten",
      "email": "xivsolutions@gmail.com"
    },
    {
      "name": "Dian Fay",
      "email": "dian.m.fay@gmail.com"
    }
  ],
  "license": "BSD",
  "dependencies": {
    "args-js": "^0.10.6",
    "async": "^0.9.0",
    "clone": "^1.0.2",
    "commander": "^2.6.0",
    "deasync": "^0.1.1",
    "glob": "^4.4.1",
    "pg": "^4.3.0",
    "pg-query-stream": "^0.7.0",
    "underscore": "^1.8.2"
  },
  "devDependencies": {
    "mocha": "^2.1.0",
    "sinon": "^1.12.2"
  },
  "repository": {
    "type": "git",
    "url": "https://github.com/robconery/massive-js.git"
  },
  "readme": "<img src=\"http://rob.conery.io/wp-content/uploads/2015/03/massive-logo.png\" width=450 />\n\n## Massive 2.0: A Postgres-centric Data Access Tool\n\n*This is the repository for MassiveJS 2.0. If you're looking for < 2, [you can find it here](https://github.com/robconery/massive-js/releases/tag/1.0)*\n\nMassive's goal is to **help** you get data from your database. This is not an ORM, it's a bit more than a query tool - our goal is to do just enough, then get out of your way. [I'm a huge fan of Postgres](http://rob.conery.io/category/postgres/) and the inspired, creative way you can use it's modern SQL functionality to work with your data.\n\nORMs abstract this away, and it's silly. Postgres is an amazing database with a rich ability to act as a document storage engine (using `jsonb`) as well as a cracking relational engine.\n\nMassive embraces SQL completely, and helps you out when you don't feel like writing another mundane `select * from` statement.\n\n## Installation\n\n```\nnpm install massive --save\n```\n\nOnce Massive is installed, you can use it by calling `connect` and passing in a callback which will give you your database instance:\n\n```javascript\nvar massive = require(\"massive\");\n\n//you can use db for 'database name' running on localhost\n//or send in everything using 'connectionString'\nmassive.connect({db : \"myDb\"}, function(err,db){\n  db.myTable.find();\n});\n```\n## Usage\n\nOne of the key features of Massive is that it loads all of your tables, Postgres functions, and local query files up as functions (this is really cool, you want this. See below for more info). Massive is fast, and does this quickly. However, there is a one-time execution penalty at intialization while all this happens. In most situations it makes sense to do this once, at application load. From there, maintain a reference to the Massive instance (Massive was conceived with this usage in mind). For example, if you are using Express as your application framework, you might do something like this:\n\n####Express Example\n\n```javascript\nvar express = require(\"express\");\nvar app = express();\nvar http = require('http');\nvar massive = require(\"massive\");\nvar connectionString = \"postgres://massive:password@localhost/chinook\";\n\n// connect to Massive and get the db instance. You can safely use the\n// convenience sync method here because its on app load\n// you can also use loadSync - it's an alias\nvar massiveInstance = massive.connectSync({connectionString : connectionString}) \n\n// Set a reference to the massive instance on Express' app:\napp.set('db', massiveInstance);\nhttp.createServer(app).listen(8080);\n```\nFrom there, accessing the db is just:\n\n```javascript\nvar db = app.get('db');\n```\n\n## SQL Files as Functions\n\nMassive supports SQL files as root-level functions. By default, if you have a `db` directory in your project (you can override this by passing in a `scripts` setting), Massive will read each SQL file therein and create a query function with the same name. If you use subdirectories, Massive will namespace your queries in the exact same way:\n\n```javascript\nvar massive = require(\"massive\");\n\nmassive.connect({\n  connectionString: \"postgres://localhost/massive\"}, function(err, db){\n  //call the productsInStock.sql file in the db/queries directory\n  db.productsInStock(function(err,products){\n    //products is a results array\n  });\n});\n```\n\nYou can use arguments right in your SQL file as well. Just format your parameters in SQL\nusing `$1`, `$2`, etc:\n\n```javascript\nvar massive = require(\"massive\");\n\nmassive.connect({db : \"myDb\"}, function(err, db){\n  //just pass in the sku as an argument\n  //your SQL would be 'select * from products where sku=$1'\n  db.productsBySku(\"XXXYYY\", function(err,products){\n    //products is a results array\n  });\n});\n```\n\nThe SQL above is, of course, rather simplistic but hopefully you get the idea: *use SQL to its fullest, we'll execute it safely for you*.\n\n## Attached Tables\n\nWhen Massive starts up it scans your tables as well and drops a queryable function on the root namespace. This means you can query your tables as if they were objects right on your db instance:\n\n```javascript\ndb.users.find(1, function(err,res){\n  //user with ID 1\n});\n```\n\nThe goal with this API is expressiveness and terseness - allowing you to think as little as possible about accessing your data.\n\n## Full Text Search Built In\n\nIf you need to query a table or a document store using Postgres' built-in Full Text Indexing, you certainly can. Just use `search` or `searchDoc` and we'll build the index on the fly:\n\n```javascript\ndb.users.search({columns :[\"email\"], term: \"rob\"}, function(err,users){\n  //all users with the word 'rob' in their email\n});\n```\n\nThis works the same for documents as well (more on documents in next section):\n\n```javascript\n//full text search...\ndb.my_documents.searchDoc({\n  keys : [\"title\", \"description\"],\n  term : \"Kauai\"\n}, function(err,docs){\n  //docs returned with an on-the-fly Full Text Search for 'Kauai'\n});\n```\n\n## Full JSONB Document Support\n\nAnother thing that is great about Postgres is the `jsonb` functionality. The queries are simple enough to write - but if you just want to encapsulate it all - we've got your back!\n\n```javascript\n//connect massive as above\nvar newDoc = {\n  title : \"Chicken Ate Nine\",\n  description: \"A book about chickens of Kauai\",\n  price : 99.00,\n  tags : [\n    {name : \"Simplicity\", slug : \"simple\"},\n    {name : \"Fun for All\", slug : \"fun-for-all\"}\n  ]\n};\n\ndb.saveDoc(\"my_documents\", newDoc, function(err,res){\n  //the table my_documents was created on the fly\n  //res is the new document with an ID created for you\n});\n\n//you can now access the document right on the root\ndb.my_documents.findDoc(1, function(err,doc){\n  //you now have access to the doc\n});\n\n//run a 'contains' query which flexes the index we created for you\ndb.my_documents.findDoc({price : 99.00}, function(err,docs){\n  //1 or more documents returned\n});\n\n//run a deep match passing an array of objects\n//again flexing the index we created for you\ndb.my_documents.findDoc({tags: [{slug : \"simple\"}]}, function(err,docs){\n  //1 or more documents returned\n});\n\n//comparative queries - these don't use indexing\ndb.my_documents.findDoc({\"price >\": 50.00}, function(err,docs){\n  //1 or more documents returned with a price > 50\n});\n\n//IN queries by passing arrays\ndb.my_documents.findDoc({id : [1,3,9]}, function(err,docs){\n  //documents with ID 1, 3, and 9\n});\n\n//NOT IN\ndb.my_documents.findDoc({\"id <>\": [3,5]}, function(err,docs){\n  //documents without ID 3 and 5\n});\n```\n\n#### A Word About IDs in Document Tables\n\nWe store IDs in their own column and treat them as a normal Primary Key. These values are **not** duplicated in the database - instead they are pulled off during writes and readded during reads.\n\n## Helpful Relational Bits\n\nThe entire API above works the same with relational tables, just remove \"Doc\" from the function name (`find`, `search`, `save`);\n\nWhen you run `connect` massive executes a quick `INFORMATION_SCHEMA` query and attaches each table to the main namespace (called `db` in these examples). You can use this to query your tables with a bit less noise.\n\nThe API is as close to Massive 1.0 as we could make it - but there's no need for `execute` - just run the query directly:\n\n```javascript\n//connect massive, get db instance\n\n//straight up SQL\ndb.run(\"select * from products where id=$1\", 1, function(err,product){\n  //product 1\n});\n\n//simplified SQL with a where\ndb.products.where(\"id=$1 OR id=$2\", [10,21], function(err,products){\n  //products 10 and 21\n});\n\n//an IN query\ndb.products.find({id : [10,21]}, function(err,products){\n  //products 10 and 21\n});\n\n//a NOT IN query\ndb.products.find({\"id <>\": [10,21]}, function(err,products){\n  //products other than 10 and 21\n});\n\n//match a JSON field\ndb.products.find({\"specs->>weight\": 30}, function(err, products) {\n  //products where the 'specs' field is a JSON document containing {weight: 30}\n  //note that the corresponding SQL query would be phrased specs->>'weight'; Massive adds the quotes for you\n})\n\n//match a JSON field with an IN list (note NOT IN is not supported for JSON fields at this time)\ndb.products.find({\"specs->>weight\": [30, 35]}, function(err, products) {\n  //products where the 'specs' field is a JSON document containing {weight: 30}\n  //note that the corresponding SQL query would be phrased specs->>'weight'; Massive adds the quotes for you\n})\n\n//drill down a JSON path\ndb.products.find({\"specs#>>{dimensions,length}\": 15}, function(err, products) {\n  //products where the 'specs' field is a JSON document having a nested 'dimensions' object containing {length: 15}\n  //note that the corresponding SQL query would be phrased specs->>'{dimensions,length}'; Massive adds the quotes for you\n})\n\n//Send in an ORDER clause by passing in a second argument\ndb.products.find({},{order: \"price desc\"} function(err,products){\n  //products ordered in descending fashion\n});\n\n//Send in an ORDER clause and a LIMIT with OFFSET\nvar options = {\n  limit : 10,\n  order : \"id\",\n  offset: 20\n}\ndb.products.find({}, options, function(err,products){\n  //products ordered in descending fashion\n});\n\n//You only want the sku and name back\nvar options = {\n  limit : 10,\n  columns : [\"sku\", \"name\"]\n}\ndb.products.find({}, options, function(err,products){\n  // an array of sku and name\n});\n\n//find a single user by id\ndb.users.findOne(1, function(err,user){\n  //returns user with id (or whatever your PK is) of 1\n});\n\n//another way to do the above\ndb.users.find(1, function(err,user){\n  //returns user with id (or whatever your PK is) of 1\n});\n\n//find first match\ndb.users.findOne({email : \"test@test.com\"}, function(err,user){\n  //returns the first match\n});\n\n//simple query\ndb.users.find({active: true}, function(err,users){\n  //all users who are active\n});\n\n//include the PK in the criteria for an update\ndb.users.save({id : 1, email : \"test@example.com\"}, function(err,updated){\n  //the updated record for the new user\n});\n\n//no PK does an INSERT\ndb.users.save({email : \"new@example.com\"}, function(err,inserted){\n  //the new record with the ID\n});\n```\n\n## Streams\n\nTo improve performance over large result sets, you might want to consider using a stream. This has the upside of returning reads right away, but the downside of leaving a connection open until you close it. To use a stream, just send in `{stream: true}` in the options:\n\n```js\ndb.users.find({company_id : 12}, {stream:true}, function(err,stream){\n\n  stream.on('readable', function(){\n    var user = stream.read();\n    //do your thing\n  });\n\n  stream.on('end', function(){\n    //deal with results here\n  });\n});\n```\n\n## Database Schema\n\nMassive understands the notion of database schemas and treats any Postgres schema other than `public` as a namespace. Objects bound to the `public` schema (the default in Postgres) are attached directly to the root db namespace. Schemas other than `public` will be represented by binding a namespace object to the root reflecting the name of the schema. To steal a previous example, let's say the `users` table was located in a back-end schema named `membership`. Massive will load up the database objects bound to the membership schema, and you can access them from code like so:\n\n```javascript\ndb.membership.users.save({email : \"new@example.com\"}, function(err,inserted){\n  //the new record with the ID\n});\n\ndb.membership.users.find({active: true}, function(err,users){\n  //all users who are active\n});\n\n```\n\n## Synchronous Methods\n\nJust about every method in Massive has a synchronous counterpart using [the deasync library](https://github.com/vkurchatkin/deasync). These methods are here for convenience when you're not worried about I/O and just want to move some data around without a callback mess.\n\n```js\nvar myUser = db.users.findOneSync({id : 1});\n```\n\n## We <3 Functions\n\nGot a ~~tightly-wound~~ super-concientous DBA who ~~micro-manages~~ carefully limits developer access to the back end store? Feel bold, adventurous, and [unconstrained by popular dogma](http://rob.conery.io/2015/02/21/its-time-to-get-over-that-stored-procedure-aversion-you-have/) about database functions/stored procedures? Unafraid to be called names by your less-enlightened friends?\n\nMassive treats Postgres functions (\"sprocs\") as first-class citizens.\n\nSay your database schema introdcues a complex peice of logic in a Postgres function:\n\n```sql\ncreate or replace function all_products()\nreturns setof products\nas\n$$\nselect * from products;\n$$\nlanguage sql;\n```\n\nMassive will load up and attach the `all_products` function, and any other Postgres function as JS functions on the root massive namespace (or on an appropriate schema-based namespace, as we just saw), which you can then access directly as functions:\n\n```javascript\ndb.all_products(function(err,res) {\n  // returns the result of the function (all the product records, in this case...)\n});\n```\nObviously, this was a trivial example, but you get the idea. You can perform complex logic deep in your database, and massive will make it accessible directly. For a deeper dive on this, see [pg-auth](https://github.com/robconery/pg-auth), which basically [rolls common membership up into a box](http://rob.conery.io/2015/03/17/membership-in-a-box-with-pg-auth/) and tucks the auth pain away behind a pleasing facade of Postgres functions. Guaranteed to stir up spirited discussions with your friends and neighbors.\n\nIf you're using a function that takes multiple parameters, you'll need to wrap your arguments in an array:\n\n```js\ndb.myFunction(['thing1', 'thing2'], function(err,res){\n  //result is always an array\n})\n```\n\n## REPL\n\nMassive has a REPL (Read Evaluate Print Loop - aka \"console\") and you can fire it up to play with your DB in the console:\n\n```\n# connect to local server, database my_database\nbin massive -d my_database\ndb >\n```\n\nFrom here you can see your tables if you like:\n\n```\ndb > db.tables\n[ { name: 'docs',\n    pk: 'id',\n    db: { connectionString: 'postgres://localhost/massive' } },\n  { name: 'products',\n    pk: 'id',\n    db: { connectionString: 'postgres://localhost/massive' } },\n  { name: 'users',\n    pk: 'id',\n    db: { connectionString: 'postgres://localhost/massive' } } ]\ndb >\n```\n\nOr just list out your queries to be sure they're being loaded:\n\n```\ndb > db.queries\n[ { [Function]\n    sql: 'select * from users where email=$1;',\n    db: { connectionString: 'postgres://localhost/massive' } } ]\ndb >\n```\n\nExecute your query to make sure it returns what you expect:\n\n```\ndb > db.queries.productById(1);\n[ {sku : 'x', name : \"Product 1\", id : '1'}]\n```\n\nBy default, Massive provides a callback for you if you don't pass one in. This automatic callback outputs the results using `console.log` so you can play with things easily.\n\n\nThere's more to do with the massive REPL - such as generating query files for you (if you're not accomplished at SQL just yet) as well as a better way to play with the results.\n\n## Want to help?\n\nThis project is just getting off the ground and could use some help with DRYing things up and refactoring.\n\nIf you want to contribute - I'd love it! Just open an issue to work against so you get full credit for your fork. You can open the issue first so we can discuss and you can work your fork as we go along.\n\nThe code is rather hideous - I wrote it in a fit of inspiration and if you see things that could be done better, yay!\n\nIf you see a bug, please be so kind as to show how it's failing, and I'll do my best to get it fixed quickly.\n",
  "readmeFilename": "README.md",
  "bugs": {
    "url": "https://github.com/robconery/massive-js/issues"
  },
  "_id": "massive@2.0.9",
  "dist": {
    "shasum": "2b6c6c0f8231d81b51536f833060d6e5a1bc1532"
  },
  "_from": "massive@",
  "_resolved": "https://registry.npmjs.org/massive/-/massive-2.0.9.tgz"
}
